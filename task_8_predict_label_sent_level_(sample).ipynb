{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XFoK9_h3D8gJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg5y7mHbB3ZO",
        "outputId": "957943c2-eb61-4105-a3b4-f9a6d11d2237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-sequence-classification\n",
            "  Downloading bert_for_sequence_classification-0.0.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (6.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (1.0.2)\n",
            "Requirement already satisfied: torch!=1.10,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from bert-for-sequence-classification) (1.12.1+cu113)\n",
            "Collecting transformers>=4.2.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.9->bert-for-sequence-classification) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bert-for-sequence-classification) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bert-for-sequence-classification) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bert-for-sequence-classification) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->bert-for-sequence-classification) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->bert-for-sequence-classification) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->bert-for-sequence-classification) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.10,>=1.7.1->bert-for-sequence-classification) (4.1.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->bert-for-sequence-classification) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.2.0->bert-for-sequence-classification) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.2.0->bert-for-sequence-classification) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.2.0->bert-for-sequence-classification) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.2.0->bert-for-sequence-classification) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.2.0->bert-for-sequence-classification) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.2.0->bert-for-sequence-classification) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, bert-for-sequence-classification\n",
            "Successfully installed bert-for-sequence-classification-0.0.4 huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "! pip install bert-for-sequence-classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import json\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "from bert_clf import BertCLF, train_evaluate, predict_metrics, prepare_data_notebook, prepare_dataset\n",
        "from bert_clf.utils import set_global_seed"
      ],
      "metadata": {
        "id": "odt44TV3B4EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/UP_w22/PM/task 8/sample/str1_sample_train_sent.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "p4aH9LYNB5_-",
        "outputId": "d0ead4fc-a7b0-47d0-f83b-1f7e073cec02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0 post_id subreddit_id  \\\n",
              "0             0  rpzuhe     t5_2qlaa   \n",
              "1             1  rpzuhe     t5_2qlaa   \n",
              "2             2  rpzuhe     t5_2qlaa   \n",
              "3             3  rpzuhe     t5_2qlaa   \n",
              "4             4  rpzuhe     t5_2qlaa   \n",
              "..          ...     ...          ...   \n",
              "227         227  smy7j7     t5_2s3g1   \n",
              "228         228  smy7j7     t5_2s3g1   \n",
              "229         229  smy7j7     t5_2s3g1   \n",
              "230         230  smy7j7     t5_2s3g1   \n",
              "231         231  smy7j7     t5_2s3g1   \n",
              "\n",
              "                                              Sentence     Label  \\\n",
              "0    Hey guys in new here and just had some questio...      none   \n",
              "1    After talking to some people, they think I may...   per_exp   \n",
              "2    Ever since almost a year and a half ago I have...   per_exp   \n",
              "3    I dont really get heartburn except for on occa...   per_exp   \n",
              "4    I was told they are all generally normal bacte...      none   \n",
              "..                                                 ...       ...   \n",
              "227  Post probiotics\\nSo my doc put me on probiotic...      none   \n",
              "228  I was on for 2 weeks and I kept feeling worse ...      none   \n",
              "229  I made the decision to stop and its been about...      none   \n",
              "230            I have a lot more gas then I did prior.      none   \n",
              "231                            Will this ever go away?  question   \n",
              "\n",
              "                                            Components  \n",
              "0                                                   {}  \n",
              "1    After talking to some people, they think I may...  \n",
              "2    Ever since almost a year and a half ago I have...  \n",
              "3    I dont really get heartburn except for on occa...  \n",
              "4                                                   {}  \n",
              "..                                                 ...  \n",
              "227                                                 {}  \n",
              "228                                                 {}  \n",
              "229                                                 {}  \n",
              "230                                                 {}  \n",
              "231                            Will this ever go away?  \n",
              "\n",
              "[232 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-684345d3-681c-486e-a9eb-f99ff95fcb3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post_id</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Components</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Hey guys in new here and just had some questio...</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>I was told they are all generally normal bacte...</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>227</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Post probiotics\\nSo my doc put me on probiotic...</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I was on for 2 weeks and I kept feeling worse ...</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>229</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I made the decision to stop and its been about...</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>230</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I have a lot more gas then I did prior.</td>\n",
              "      <td>none</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>231</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "      <td>question</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-684345d3-681c-486e-a9eb-f99ff95fcb3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-684345d3-681c-486e-a9eb-f99ff95fcb3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-684345d3-681c-486e-a9eb-f99ff95fcb3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid = ['claim', 'claim_per_exp', 'per_exp', 'question']\n",
        "utest = df.loc[(df['Label'].isin(valid))]"
      ],
      "metadata": {
        "id": "9Z2xpTnAB-RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1VIZm0CxCK9S",
        "outputId": "ce6ffa77-23a0-4eb3-8315-30d8a86577d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0 post_id subreddit_id  \\\n",
              "1             1  rpzuhe     t5_2qlaa   \n",
              "2             2  rpzuhe     t5_2qlaa   \n",
              "3             3  rpzuhe     t5_2qlaa   \n",
              "14           14  rpzuhe     t5_2qlaa   \n",
              "23           23  rpzuhe     t5_2qlaa   \n",
              "25           25  s5ln4e     t5_2tyg2   \n",
              "26           26  s5ln4e     t5_2tyg2   \n",
              "28           28  ptzw1x     t5_2r876   \n",
              "44           44  ptzw1x     t5_2r876   \n",
              "60           60  ptzw1x     t5_2r876   \n",
              "75           75  ptzw1x     t5_2r876   \n",
              "90           90  ptzw1x     t5_2r876   \n",
              "91           91  ptzw1x     t5_2r876   \n",
              "92           92  ptzw1x     t5_2r876   \n",
              "93           93  ptzw1x     t5_2r876   \n",
              "94           94  ptzw1x     t5_2r876   \n",
              "95           95  ptzw1x     t5_2r876   \n",
              "101         101  ryrrom     t5_2rtve   \n",
              "107         107  ryrrom     t5_2rtve   \n",
              "109         109  rd97yi     t5_2syer   \n",
              "116         116  rd97yi     t5_2syer   \n",
              "125         125  rd97yi     t5_2syer   \n",
              "126         126  rd97yi     t5_2syer   \n",
              "129         129  s3bfss     t5_2saq9   \n",
              "137         137  s3bfss     t5_2saq9   \n",
              "138         138  s3bfss     t5_2saq9   \n",
              "140         140  srtnup     t5_2r876   \n",
              "164         164  srtnup     t5_2r876   \n",
              "165         165  srtnup     t5_2r876   \n",
              "166         166  srtnup     t5_2r876   \n",
              "194         194  srtnup     t5_2r876   \n",
              "195         195  srtnup     t5_2r876   \n",
              "218         218  srtnup     t5_2r876   \n",
              "219         219  srtnup     t5_2r876   \n",
              "222         222  smy7j7     t5_2s3g1   \n",
              "223         223  smy7j7     t5_2s3g1   \n",
              "224         224  smy7j7     t5_2s3g1   \n",
              "225         225  smy7j7     t5_2s3g1   \n",
              "231         231  smy7j7     t5_2s3g1   \n",
              "\n",
              "                                              Sentence          Label  \\\n",
              "1    After talking to some people, they think I may...        per_exp   \n",
              "2    Ever since almost a year and a half ago I have...        per_exp   \n",
              "3    I dont really get heartburn except for on occa...        per_exp   \n",
              "14   It has caused me to have swollen taste buds an...        per_exp   \n",
              "23               Anyone else have these same problems?       question   \n",
              "25   No episodes during my stay in psych ward until...        per_exp   \n",
              "26   I got myself admitted due to thinking of harmi...        per_exp   \n",
              "28   Looking for some positive experiences\\nSometim...          claim   \n",
              "44   Was there a time someone made a generous accom...       question   \n",
              "60   Did you have an experience you wouldn't have o...       question   \n",
              "75   Did a relationship take on a different level b...       question   \n",
              "90   For me, a time that stands out is when I was i...        per_exp   \n",
              "91   I was a hardworking student who had maintained...        per_exp   \n",
              "92   I'd been in the hospital several times through...        per_exp   \n",
              "93   At the end of Grade 10, I was hospitalized at ...        per_exp   \n",
              "94   I studied on my own as best I could, but I mis...        per_exp   \n",
              "95   When it came time for the test, I got a much l...        per_exp   \n",
              "101  Edible thoughts\\nWhy cant we have a Lupus pump...       question   \n",
              "107                               For example Insulin?       question   \n",
              "109  Primary care physician PCP\\nMy fellow gout suf...        per_exp   \n",
              "116  My dad also suffers from gout and hes on allop...        per_exp   \n",
              "125  What do you think should I go see him or shoul...       question   \n",
              "126                            Thank you for your help       question   \n",
              "129  It's more expensive then Walmart but closer th...        per_exp   \n",
              "137            At least I have electrolyte drinks now.        per_exp   \n",
              "138                        And I got salt, salty salt.        per_exp   \n",
              "140  What's the best, highest g sugar, most compact...       question   \n",
              "164  So, as I have gastroparesis, glucose tabs don'...  claim_per_exp   \n",
              "165  They take over a half hour to kick in, and I e...  claim_per_exp   \n",
              "166                So I have to drink liquid to treat.  claim_per_exp   \n",
              "194  Possibly I could make really concentrated suga...       question   \n",
              "195  And how long would that keep before it goes ra...       question   \n",
              "218  So my question is what can I bring along with ...       question   \n",
              "219                            What's your experience?       question   \n",
              "222  Post probiotics\\nSo my doc put me on probiotic...  claim_per_exp   \n",
              "223  I was on for 2 weeks and I kept feeling worse ...  claim_per_exp   \n",
              "224  I made the decision to stop and its been about...  claim_per_exp   \n",
              "225            I have a lot more gas then I did prior.  claim_per_exp   \n",
              "231                            Will this ever go away?       question   \n",
              "\n",
              "                                            Components  \n",
              "1    After talking to some people, they think I may...  \n",
              "2    Ever since almost a year and a half ago I have...  \n",
              "3    I dont really get heartburn except for on occa...  \n",
              "14   It has caused me to have swollen taste buds an...  \n",
              "23                Anyone else have these same problems  \n",
              "25   Before getting admitted to psych ward I had ep...  \n",
              "26   I got myself admitted due to thinking of harmi...  \n",
              "28   Sometimes the CF community in general can get ...  \n",
              "44   Was there a time someone made a generous accom...  \n",
              "60   Did you have an experience you wouldn't have o...  \n",
              "75   \\nDid a relationship take on a different level...  \n",
              "90   For me, a time that stands out is when I was i...  \n",
              "91   10. I was a hardworking student who had mainta...  \n",
              "92    8. I'd been in the hospital several times thr...  \n",
              "93   ay. At the end of Grade 10, I was hospitalized...  \n",
              "94   ct. I studied on my own as best I could, but I...  \n",
              "95   ct. When it came time for the test, I got a mu...  \n",
              "101              Why cant we have a Lupus pump/patch??  \n",
              "107                               For example Insulin?  \n",
              "109  My fellow gout suffers Im 50 years old will be...  \n",
              "116  My dad also suffers from gout and hes on allop...  \n",
              "125  What do you think should I go see him or shoul...  \n",
              "126                                              gist?  \n",
              "129                             chance of passing out.  \n",
              "137                     I have electrolyte drinks now.  \n",
              "138                     \\n\\n And I got salt, salty sal  \n",
              "140  What's the best, highest g sugar, most compact...  \n",
              "164  So, as I have gastroparesis, glucose tabs don'...  \n",
              "165   They take over a half hour to kick in, and I ...  \n",
              "166                 So I have to drink liquid to treat  \n",
              "194  Possibly I could make really concentrated suga...  \n",
              "195  g? And how long would that keep before it goes...  \n",
              "218  So my question is what can I bring along with ...  \n",
              "219                                            uickly?  \n",
              "222             So my doc put me on probiotics VSL 3.   \n",
              "223  I was on for 2 weeks and I kept feeling worse ...  \n",
              "224  I made the decision to stop and its been about...  \n",
              "225             I have a lot more gas then I did prior  \n",
              "231                            Will this ever go away?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0808809b-cf9f-4c80-8732-1c93a5f3348c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post_id</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Components</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>It has caused me to have swollen taste buds an...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>It has caused me to have swollen taste buds an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Anyone else have these same problems?</td>\n",
              "      <td>question</td>\n",
              "      <td>Anyone else have these same problems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>s5ln4e</td>\n",
              "      <td>t5_2tyg2</td>\n",
              "      <td>No episodes during my stay in psych ward until...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>Before getting admitted to psych ward I had ep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>s5ln4e</td>\n",
              "      <td>t5_2tyg2</td>\n",
              "      <td>I got myself admitted due to thinking of harmi...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>I got myself admitted due to thinking of harmi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Looking for some positive experiences\\nSometim...</td>\n",
              "      <td>claim</td>\n",
              "      <td>Sometimes the CF community in general can get ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Was there a time someone made a generous accom...</td>\n",
              "      <td>question</td>\n",
              "      <td>Was there a time someone made a generous accom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Did you have an experience you wouldn't have o...</td>\n",
              "      <td>question</td>\n",
              "      <td>Did you have an experience you wouldn't have o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Did a relationship take on a different level b...</td>\n",
              "      <td>question</td>\n",
              "      <td>\\nDid a relationship take on a different level...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>For me, a time that stands out is when I was i...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>For me, a time that stands out is when I was i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I was a hardworking student who had maintained...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>10. I was a hardworking student who had mainta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I'd been in the hospital several times through...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>8. I'd been in the hospital several times thr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>At the end of Grade 10, I was hospitalized at ...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>ay. At the end of Grade 10, I was hospitalized...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I studied on my own as best I could, but I mis...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>ct. I studied on my own as best I could, but I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>When it came time for the test, I got a much l...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>ct. When it came time for the test, I got a mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>ryrrom</td>\n",
              "      <td>t5_2rtve</td>\n",
              "      <td>Edible thoughts\\nWhy cant we have a Lupus pump...</td>\n",
              "      <td>question</td>\n",
              "      <td>Why cant we have a Lupus pump/patch??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>107</td>\n",
              "      <td>ryrrom</td>\n",
              "      <td>t5_2rtve</td>\n",
              "      <td>For example Insulin?</td>\n",
              "      <td>question</td>\n",
              "      <td>For example Insulin?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>109</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>Primary care physician PCP\\nMy fellow gout suf...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>My fellow gout suffers Im 50 years old will be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>My dad also suffers from gout and hes on allop...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>My dad also suffers from gout and hes on allop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>What do you think should I go see him or shoul...</td>\n",
              "      <td>question</td>\n",
              "      <td>What do you think should I go see him or shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>Thank you for your help</td>\n",
              "      <td>question</td>\n",
              "      <td>gist?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>129</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>It's more expensive then Walmart but closer th...</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>chance of passing out.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>137</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>At least I have electrolyte drinks now.</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>I have electrolyte drinks now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>138</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>And I got salt, salty salt.</td>\n",
              "      <td>per_exp</td>\n",
              "      <td>\\n\\n And I got salt, salty sal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>140</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>What's the best, highest g sugar, most compact...</td>\n",
              "      <td>question</td>\n",
              "      <td>What's the best, highest g sugar, most compact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>164</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So, as I have gastroparesis, glucose tabs don'...</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>So, as I have gastroparesis, glucose tabs don'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>165</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>They take over a half hour to kick in, and I e...</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>They take over a half hour to kick in, and I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>166</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So I have to drink liquid to treat.</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>So I have to drink liquid to treat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>194</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Possibly I could make really concentrated suga...</td>\n",
              "      <td>question</td>\n",
              "      <td>Possibly I could make really concentrated suga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>195</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>And how long would that keep before it goes ra...</td>\n",
              "      <td>question</td>\n",
              "      <td>g? And how long would that keep before it goes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>218</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So my question is what can I bring along with ...</td>\n",
              "      <td>question</td>\n",
              "      <td>So my question is what can I bring along with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>219</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>What's your experience?</td>\n",
              "      <td>question</td>\n",
              "      <td>uickly?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>222</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Post probiotics\\nSo my doc put me on probiotic...</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>So my doc put me on probiotics VSL 3.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>223</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I was on for 2 weeks and I kept feeling worse ...</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>I was on for 2 weeks and I kept feeling worse ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>224</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I made the decision to stop and its been about...</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>I made the decision to stop and its been about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>225</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I have a lot more gas then I did prior.</td>\n",
              "      <td>claim_per_exp</td>\n",
              "      <td>I have a lot more gas then I did prior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>231</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "      <td>question</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0808809b-cf9f-4c80-8732-1c93a5f3348c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0808809b-cf9f-4c80-8732-1c93a5f3348c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0808809b-cf9f-4c80-8732-1c93a5f3348c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ['claim', 'claim_per_exp', 'per_exp', 'question']\n",
        "\n",
        "utest['Label'] = utest['Label'].str.replace('claim_per_exp','Claim Per Experience')\n",
        "utest['Label'] = utest['Label'].str.replace('claim','Claim')\n",
        "utest['Label'] = utest['Label'].str.replace('per_exp','Per Experience')\n",
        "utest['Label'] = utest['Label'].str.replace('question','Question')\n",
        "utest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5W8aPMNOCMRb",
        "outputId": "7e0c252a-6c16-43ca-b273-6a07bf876827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0 post_id subreddit_id  \\\n",
              "1             1  rpzuhe     t5_2qlaa   \n",
              "2             2  rpzuhe     t5_2qlaa   \n",
              "3             3  rpzuhe     t5_2qlaa   \n",
              "14           14  rpzuhe     t5_2qlaa   \n",
              "23           23  rpzuhe     t5_2qlaa   \n",
              "25           25  s5ln4e     t5_2tyg2   \n",
              "26           26  s5ln4e     t5_2tyg2   \n",
              "28           28  ptzw1x     t5_2r876   \n",
              "44           44  ptzw1x     t5_2r876   \n",
              "60           60  ptzw1x     t5_2r876   \n",
              "75           75  ptzw1x     t5_2r876   \n",
              "90           90  ptzw1x     t5_2r876   \n",
              "91           91  ptzw1x     t5_2r876   \n",
              "92           92  ptzw1x     t5_2r876   \n",
              "93           93  ptzw1x     t5_2r876   \n",
              "94           94  ptzw1x     t5_2r876   \n",
              "95           95  ptzw1x     t5_2r876   \n",
              "101         101  ryrrom     t5_2rtve   \n",
              "107         107  ryrrom     t5_2rtve   \n",
              "109         109  rd97yi     t5_2syer   \n",
              "116         116  rd97yi     t5_2syer   \n",
              "125         125  rd97yi     t5_2syer   \n",
              "126         126  rd97yi     t5_2syer   \n",
              "129         129  s3bfss     t5_2saq9   \n",
              "137         137  s3bfss     t5_2saq9   \n",
              "138         138  s3bfss     t5_2saq9   \n",
              "140         140  srtnup     t5_2r876   \n",
              "164         164  srtnup     t5_2r876   \n",
              "165         165  srtnup     t5_2r876   \n",
              "166         166  srtnup     t5_2r876   \n",
              "194         194  srtnup     t5_2r876   \n",
              "195         195  srtnup     t5_2r876   \n",
              "218         218  srtnup     t5_2r876   \n",
              "219         219  srtnup     t5_2r876   \n",
              "222         222  smy7j7     t5_2s3g1   \n",
              "223         223  smy7j7     t5_2s3g1   \n",
              "224         224  smy7j7     t5_2s3g1   \n",
              "225         225  smy7j7     t5_2s3g1   \n",
              "231         231  smy7j7     t5_2s3g1   \n",
              "\n",
              "                                              Sentence                 Label  \\\n",
              "1    After talking to some people, they think I may...        Per Experience   \n",
              "2    Ever since almost a year and a half ago I have...        Per Experience   \n",
              "3    I dont really get heartburn except for on occa...        Per Experience   \n",
              "14   It has caused me to have swollen taste buds an...        Per Experience   \n",
              "23               Anyone else have these same problems?              Question   \n",
              "25   No episodes during my stay in psych ward until...        Per Experience   \n",
              "26   I got myself admitted due to thinking of harmi...        Per Experience   \n",
              "28   Looking for some positive experiences\\nSometim...                 Claim   \n",
              "44   Was there a time someone made a generous accom...              Question   \n",
              "60   Did you have an experience you wouldn't have o...              Question   \n",
              "75   Did a relationship take on a different level b...              Question   \n",
              "90   For me, a time that stands out is when I was i...        Per Experience   \n",
              "91   I was a hardworking student who had maintained...        Per Experience   \n",
              "92   I'd been in the hospital several times through...        Per Experience   \n",
              "93   At the end of Grade 10, I was hospitalized at ...        Per Experience   \n",
              "94   I studied on my own as best I could, but I mis...        Per Experience   \n",
              "95   When it came time for the test, I got a much l...        Per Experience   \n",
              "101  Edible thoughts\\nWhy cant we have a Lupus pump...              Question   \n",
              "107                               For example Insulin?              Question   \n",
              "109  Primary care physician PCP\\nMy fellow gout suf...        Per Experience   \n",
              "116  My dad also suffers from gout and hes on allop...        Per Experience   \n",
              "125  What do you think should I go see him or shoul...              Question   \n",
              "126                            Thank you for your help              Question   \n",
              "129  It's more expensive then Walmart but closer th...        Per Experience   \n",
              "137            At least I have electrolyte drinks now.        Per Experience   \n",
              "138                        And I got salt, salty salt.        Per Experience   \n",
              "140  What's the best, highest g sugar, most compact...              Question   \n",
              "164  So, as I have gastroparesis, glucose tabs don'...  Claim Per Experience   \n",
              "165  They take over a half hour to kick in, and I e...  Claim Per Experience   \n",
              "166                So I have to drink liquid to treat.  Claim Per Experience   \n",
              "194  Possibly I could make really concentrated suga...              Question   \n",
              "195  And how long would that keep before it goes ra...              Question   \n",
              "218  So my question is what can I bring along with ...              Question   \n",
              "219                            What's your experience?              Question   \n",
              "222  Post probiotics\\nSo my doc put me on probiotic...  Claim Per Experience   \n",
              "223  I was on for 2 weeks and I kept feeling worse ...  Claim Per Experience   \n",
              "224  I made the decision to stop and its been about...  Claim Per Experience   \n",
              "225            I have a lot more gas then I did prior.  Claim Per Experience   \n",
              "231                            Will this ever go away?              Question   \n",
              "\n",
              "                                            Components  \n",
              "1    After talking to some people, they think I may...  \n",
              "2    Ever since almost a year and a half ago I have...  \n",
              "3    I dont really get heartburn except for on occa...  \n",
              "14   It has caused me to have swollen taste buds an...  \n",
              "23                Anyone else have these same problems  \n",
              "25   Before getting admitted to psych ward I had ep...  \n",
              "26   I got myself admitted due to thinking of harmi...  \n",
              "28   Sometimes the CF community in general can get ...  \n",
              "44   Was there a time someone made a generous accom...  \n",
              "60   Did you have an experience you wouldn't have o...  \n",
              "75   \\nDid a relationship take on a different level...  \n",
              "90   For me, a time that stands out is when I was i...  \n",
              "91   10. I was a hardworking student who had mainta...  \n",
              "92    8. I'd been in the hospital several times thr...  \n",
              "93   ay. At the end of Grade 10, I was hospitalized...  \n",
              "94   ct. I studied on my own as best I could, but I...  \n",
              "95   ct. When it came time for the test, I got a mu...  \n",
              "101              Why cant we have a Lupus pump/patch??  \n",
              "107                               For example Insulin?  \n",
              "109  My fellow gout suffers Im 50 years old will be...  \n",
              "116  My dad also suffers from gout and hes on allop...  \n",
              "125  What do you think should I go see him or shoul...  \n",
              "126                                              gist?  \n",
              "129                             chance of passing out.  \n",
              "137                     I have electrolyte drinks now.  \n",
              "138                     \\n\\n And I got salt, salty sal  \n",
              "140  What's the best, highest g sugar, most compact...  \n",
              "164  So, as I have gastroparesis, glucose tabs don'...  \n",
              "165   They take over a half hour to kick in, and I ...  \n",
              "166                 So I have to drink liquid to treat  \n",
              "194  Possibly I could make really concentrated suga...  \n",
              "195  g? And how long would that keep before it goes...  \n",
              "218  So my question is what can I bring along with ...  \n",
              "219                                            uickly?  \n",
              "222             So my doc put me on probiotics VSL 3.   \n",
              "223  I was on for 2 weeks and I kept feeling worse ...  \n",
              "224  I made the decision to stop and its been about...  \n",
              "225             I have a lot more gas then I did prior  \n",
              "231                            Will this ever go away?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e22d8465-b1f1-4c77-9f22-2d82060ac3f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post_id</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Components</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>After talking to some people, they think I may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>Ever since almost a year and a half ago I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>I dont really get heartburn except for on occa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>It has caused me to have swollen taste buds an...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>It has caused me to have swollen taste buds an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>rpzuhe</td>\n",
              "      <td>t5_2qlaa</td>\n",
              "      <td>Anyone else have these same problems?</td>\n",
              "      <td>Question</td>\n",
              "      <td>Anyone else have these same problems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>s5ln4e</td>\n",
              "      <td>t5_2tyg2</td>\n",
              "      <td>No episodes during my stay in psych ward until...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>Before getting admitted to psych ward I had ep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>s5ln4e</td>\n",
              "      <td>t5_2tyg2</td>\n",
              "      <td>I got myself admitted due to thinking of harmi...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>I got myself admitted due to thinking of harmi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Looking for some positive experiences\\nSometim...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Sometimes the CF community in general can get ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Was there a time someone made a generous accom...</td>\n",
              "      <td>Question</td>\n",
              "      <td>Was there a time someone made a generous accom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Did you have an experience you wouldn't have o...</td>\n",
              "      <td>Question</td>\n",
              "      <td>Did you have an experience you wouldn't have o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Did a relationship take on a different level b...</td>\n",
              "      <td>Question</td>\n",
              "      <td>\\nDid a relationship take on a different level...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>For me, a time that stands out is when I was i...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>For me, a time that stands out is when I was i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I was a hardworking student who had maintained...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>10. I was a hardworking student who had mainta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I'd been in the hospital several times through...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>8. I'd been in the hospital several times thr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>At the end of Grade 10, I was hospitalized at ...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>ay. At the end of Grade 10, I was hospitalized...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>I studied on my own as best I could, but I mis...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>ct. I studied on my own as best I could, but I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>ptzw1x</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>When it came time for the test, I got a much l...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>ct. When it came time for the test, I got a mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>ryrrom</td>\n",
              "      <td>t5_2rtve</td>\n",
              "      <td>Edible thoughts\\nWhy cant we have a Lupus pump...</td>\n",
              "      <td>Question</td>\n",
              "      <td>Why cant we have a Lupus pump/patch??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>107</td>\n",
              "      <td>ryrrom</td>\n",
              "      <td>t5_2rtve</td>\n",
              "      <td>For example Insulin?</td>\n",
              "      <td>Question</td>\n",
              "      <td>For example Insulin?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>109</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>Primary care physician PCP\\nMy fellow gout suf...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>My fellow gout suffers Im 50 years old will be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>My dad also suffers from gout and hes on allop...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>My dad also suffers from gout and hes on allop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>What do you think should I go see him or shoul...</td>\n",
              "      <td>Question</td>\n",
              "      <td>What do you think should I go see him or shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>rd97yi</td>\n",
              "      <td>t5_2syer</td>\n",
              "      <td>Thank you for your help</td>\n",
              "      <td>Question</td>\n",
              "      <td>gist?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>129</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>It's more expensive then Walmart but closer th...</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>chance of passing out.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>137</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>At least I have electrolyte drinks now.</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>I have electrolyte drinks now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>138</td>\n",
              "      <td>s3bfss</td>\n",
              "      <td>t5_2saq9</td>\n",
              "      <td>And I got salt, salty salt.</td>\n",
              "      <td>Per Experience</td>\n",
              "      <td>\\n\\n And I got salt, salty sal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>140</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>What's the best, highest g sugar, most compact...</td>\n",
              "      <td>Question</td>\n",
              "      <td>What's the best, highest g sugar, most compact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>164</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So, as I have gastroparesis, glucose tabs don'...</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>So, as I have gastroparesis, glucose tabs don'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>165</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>They take over a half hour to kick in, and I e...</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>They take over a half hour to kick in, and I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>166</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So I have to drink liquid to treat.</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>So I have to drink liquid to treat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>194</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>Possibly I could make really concentrated suga...</td>\n",
              "      <td>Question</td>\n",
              "      <td>Possibly I could make really concentrated suga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>195</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>And how long would that keep before it goes ra...</td>\n",
              "      <td>Question</td>\n",
              "      <td>g? And how long would that keep before it goes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>218</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>So my question is what can I bring along with ...</td>\n",
              "      <td>Question</td>\n",
              "      <td>So my question is what can I bring along with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>219</td>\n",
              "      <td>srtnup</td>\n",
              "      <td>t5_2r876</td>\n",
              "      <td>What's your experience?</td>\n",
              "      <td>Question</td>\n",
              "      <td>uickly?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>222</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Post probiotics\\nSo my doc put me on probiotic...</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>So my doc put me on probiotics VSL 3.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>223</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I was on for 2 weeks and I kept feeling worse ...</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>I was on for 2 weeks and I kept feeling worse ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>224</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I made the decision to stop and its been about...</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>I made the decision to stop and its been about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>225</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>I have a lot more gas then I did prior.</td>\n",
              "      <td>Claim Per Experience</td>\n",
              "      <td>I have a lot more gas then I did prior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>231</td>\n",
              "      <td>smy7j7</td>\n",
              "      <td>t5_2s3g1</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "      <td>Question</td>\n",
              "      <td>Will this ever go away?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e22d8465-b1f1-4c77-9f22-2d82060ac3f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e22d8465-b1f1-4c77-9f22-2d82060ac3f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e22d8465-b1f1-4c77-9f22-2d82060ac3f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(columns=['Sentence', 'Label'])\n",
        "df_test = pd.DataFrame(columns=['Sentence', 'Label'])\n",
        "df_value = pd.DataFrame(columns=['Sentence', 'Label'])\n",
        "split = int(232*0.8)\n",
        "for index, row in df.iterrows():\n",
        "  if index < split:\n",
        "    df_train = df_train.append({'Sentence': row['Sentence'], 'Label': row[\"Label\"]},ignore_index=True)\n",
        "\n",
        "  if index >= split:\n",
        "    df_test = df_test.append({'Sentence': row['Sentence'], 'Label': row[\"Label\"]},ignore_index=True)\n",
        "\n",
        "  df_value = df_value.append({'Sentence': row['Sentence'], 'Label': row[\"Label\"]},ignore_index=True)\n",
        "\n",
        "\n",
        "print(df_train.shape, df_value.shape, df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkXtj11JChir",
        "outputId": "25ed3394-5ee6-45b8-ab47-ab853e61bef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(185, 2) (232, 2) (47, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    transformer_model = dict(\n",
        "        model = \"roberta-base\",\n",
        "        path_to_state_dict = False,\n",
        "        device = 'cuda',\n",
        "        dropout = 0.2,\n",
        "        learning_rate = 2e-6,\n",
        "        batch_size = 16,\n",
        "        shuffle = True,\n",
        "        maxlen = 128,\n",
        "    ),\n",
        "    data = dict(\n",
        "        train_data_path = df_train,\n",
        "        test_data_path = df_value,\n",
        "        text_column = \"Sentence\",\n",
        "        target_column = \"Label\",\n",
        "        random_state = 20,\n",
        "        test_size = 0.3,\n",
        "        stratify=True\n",
        "    ),\n",
        "    training = dict (\n",
        "    save_state_dict = False, # if False the model will be saved using torch.save()\n",
        "        # and should be loaded like this: model = torch.load()\n",
        "        # you will have to install the library to do so\n",
        "    early_stopping = True,\n",
        "    delta = 0.001,\n",
        "    patience = 7,\n",
        "    num_epochs = 2,\n",
        "    average_f1 = 'macro',\n",
        "    other_metrics = ['micro', 'weighted'],\n",
        "    output_dir = \"../results/\",\n",
        "    class_weight = True\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "nzIT0r_ICnfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(seed=config['data']['random_state'])\n",
        "os.makedirs(config['training']['output_dir'], exist_ok=True)"
      ],
      "metadata": {
        "id": "5dDscBaACrPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(config['transformer_model']['device'])\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        pretrained_model_name_or_path=config['transformer_model'][\"model\"]\n",
        "    )\n",
        "model_bert = AutoModel.from_pretrained(\n",
        "    pretrained_model_name_or_path=config['transformer_model'][\"model\"]\n",
        ").to(device)\n",
        "\n",
        "#for param in model_bert.parameters():\n",
        "    #param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z3L7ZrWCtN2",
        "outputId": "46b3027a-35eb-44a8-c95e-a2ea2e829695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label, train_texts, valid_texts, train_targets, valid_targets = prepare_data_notebook(\n",
        "    config=config, train_df = df_train, test_df = df_value\n",
        ")"
      ],
      "metadata": {
        "id": "GghYg9NaCuYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertCLF(\n",
        "    pretrained_model=model_bert,\n",
        "    tokenizer=tokenizer,\n",
        "    id2label=id2label,\n",
        "    dropout=config['transformer_model']['dropout'],\n",
        "    device=device     \n",
        "    )"
      ],
      "metadata": {
        "id": "hu04yNUcCvot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "HAphxgmrCwh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=float(config['transformer_model']['learning_rate']))\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "training_generator, valid_generator = prepare_dataset(\n",
        "    tokenizer=tokenizer,\n",
        "    train_texts=train_texts,\n",
        "    train_targets=train_targets,\n",
        "    valid_texts=valid_texts,\n",
        "    valid_targets=valid_targets,\n",
        "    config=config\n",
        ")"
      ],
      "metadata": {
        "id": "wbweK_yUCxeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_evaluate(\n",
        "    model=model,\n",
        "    training_generator=training_generator,\n",
        "    valid_generator=valid_generator,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=config['training']['num_epochs'],\n",
        "    average=config['training']['average_f1'],\n",
        "    config=config\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2DuuAH_Cytk",
        "outputId": "3514ced2-e5f6-4358-9f29-52a1c0895fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Epoch 1 out of 2 ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training loop: 100%|██████████| 12/12 [00:04<00:00,  2.55it/s]\n",
            "Evaluating loop: 100%|██████████| 15/15 [00:00<00:00, 17.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1: 0.08253065221815221\n",
            "Eval F1: 0.043400986125444324\n",
            "\n",
            "Train F1 micro: 0.11226851851851853\n",
            "Eval F1 micro: 0.07083333333333333\n",
            "\n",
            "Train F1 weighted: 0.0823682972120472\n",
            "Eval F1 weighted: 0.015167411994037379\n",
            "\n",
            "==== Epoch 2 out of 2 ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training loop: 100%|██████████| 12/12 [00:02<00:00,  5.55it/s]\n",
            "Evaluating loop: 100%|██████████| 15/15 [00:00<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1: 0.1575202776979738\n",
            "Eval F1: 0.04517066085693537\n",
            "\n",
            "Train F1 micro: 0.24016203703703706\n",
            "Eval F1 micro: 0.07083333333333333\n",
            "\n",
            "Train F1 weighted: 0.2799151752046973\n",
            "Eval F1 weighted: 0.01181917211328976\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing final metrics...: 100%|██████████| 15/15 [00:00<00:00, 21.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        claim       0.00      0.00      0.00         1\n",
            "claim_per_exp       0.00      0.00      0.00         7\n",
            "         none       0.00      0.00      0.00       193\n",
            "      per_exp       0.07      1.00      0.14        17\n",
            "     question       0.00      0.00      0.00        14\n",
            "\n",
            "     accuracy                           0.07       232\n",
            "    macro avg       0.01      0.20      0.03       232\n",
            " weighted avg       0.01      0.07      0.01       232\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vqBhEiHC7DK",
        "outputId": "3eb61e9a-eedf-4302-8aae-272e7d32a7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertCLF(\n",
              "  (pretrained_model): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (act): LogSoftmax(dim=1)\n",
              "  (fc): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for i,j in zip(df_test['Sentence'], df_test['Label']):\n",
        "    preds.append([model.predict(i), j, i])"
      ],
      "metadata": {
        "id": "TSBWSm4nC-ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in preds:\n",
        "    pred.append(i[0])\n",
        "\n",
        "true = []\n",
        "for m in preds:\n",
        "    true.append(m[1])"
      ],
      "metadata": {
        "id": "iMoQtE9jDBPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 4','class 3','class 2','class 1', 'class 0']\n",
        "print(classification_report(true, pred, target_names=target_names, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyA8HhD4DBe4",
        "outputId": "b3c0f3b0-61bc-450f-e540-00e6599aaac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 3      0.000     0.000     0.000       4.0\n",
            "     class 2      0.000     0.000     0.000      38.0\n",
            "     class 1      0.000     0.000     0.000       0.0\n",
            "     class 0      0.000     0.000     0.000       5.0\n",
            "\n",
            "    accuracy                          0.000      47.0\n",
            "   macro avg      0.000     0.000     0.000      47.0\n",
            "weighted avg      0.000     0.000     0.000      47.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for i,j in zip(utest['Sentence'], utest['Label']):\n",
        "    preds.append([model.predict(i), j, i])"
      ],
      "metadata": {
        "id": "mG8zVC87DH9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in preds:\n",
        "    pred.append(i[0])\n",
        "\n",
        "true = []\n",
        "for m in preds:\n",
        "    true.append(m[1])"
      ],
      "metadata": {
        "id": "-X7AS5QvDI_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 4','class 3','class 2','class 1', 'class 0']\n",
        "print(classification_report(true, pred, target_names=target_names, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl3JCMp8DJPL",
        "outputId": "62f7ed7c-4641-4639-b991-a76c9cd8957b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 4      0.000     0.000     0.000       1.0\n",
            "     class 3      0.000     0.000     0.000       7.0\n",
            "     class 2      0.000     0.000     0.000      17.0\n",
            "     class 1      0.000     0.000     0.000      14.0\n",
            "     class 0      0.000     0.000     0.000       0.0\n",
            "\n",
            "    accuracy                          0.000      39.0\n",
            "   macro avg      0.000     0.000     0.000      39.0\n",
            "weighted avg      0.000     0.000     0.000      39.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dummy = np.ones(3814)"
      ],
      "metadata": {
        "id": "yR3Vz5iuDPgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline for task 2 on Ukraine data \n",
        "target_names = ['class 3','class 2','class 1', 'class 0']\n",
        "print(classification_report(true, dummy, target_names=target_names, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "m63w8SIJDQsV",
        "outputId": "1250c605-834c-477c-ba80-1851e50c2dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-adf4d143f135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# baseline for task 2 on Ukraine data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'class 3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'class 2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'class 1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'true' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hIRve-htDR8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}